---
title:  "2017-06-15-CS350"
date:   2017-06-15 00:00:00 -0400
categories: CS350
layout: post
---
## CS350, 2017-06-15


#### Large, Sparse Virtual Memories

Virtual memory may be very large

* MIPS: V=32, max virtual memory size is `2^32` bytes (4GB)
* x86-64: V=48, max virtual memory size is `2^48` bytes (256TB)

Much of the virtual memory may be unused

* `testbin/sort` needs only about 1.2MB of the full 4GB virtual memory it runs in
* The amount of data we might be allocating for virtual memory pales in comparison to the amount of memory we actually need

Application may use *discontiguous* segments of the virtual memory

* In the `testbin/sort` address space, the data and stack segments are widely spaced
    - why?
        + ...


#### Limitations of Simple Address Translation Approaches

* A kernel that uses simple dynamic relocation would have to allocate 2GB of contiguous physical memory for `testbin/sort` virtual memory
    - even though `sort` only uses about 1.2MB
* A kernel that uses simple paging would require a page table with 2^20 PTEs (assuming page size is 4KB) to map `testbin/sort` address space
    - this page table is larger than the virtual memory that sort needs to use...
    - most of the PTEs are marked invalid
    - this page table has to be contiguous in kernel memory



### Segmentation


* Instead of mapping the entire v.mem to physical, we can provide a separate mapping for each __segment__ of the virtual memory that the application actually uses
    - from slide vm_28, we don't need to keep track of the near 4GB of wasted/unused addresses
    - what if we only stored the mapping for the red, green, and blue memory sections?
* Instead of a single offset and limit for the __entire__ address space, the kernel maintains an offset and limit for each segment
    - If I have 3 segments: code, data, stack, my MMU will have 3 sets of registers
        + for translation, need to determine which segment an address belongs to
        + then, do simple dynamic relocation math to translate the v.addr to phys.addr
* With segmentation, a v.addr can be thought of as having two parts
    - segment ID
    - offset within segment
* with K bits for the segment ID, we can have up to
    - 2^K segments
    - 2^(V-K) bytes per segment
* The kernel decides where each segment is placed in physical memory
    - fragmentation of physical memory is possible again, although the trade-off seems worth it

```
\# segments
\# bits for segment number = ceil(log(# segments))

see [vm_S32]
```

#### Translating Segmented Virtual Addresses

* The MMU needs a relocation register and a limit register for each segment
    - let `Ri` be the relocation offset for the `i`th segment
    - let `Li` be the limit for the `i`th segment
* To translate v.addr `v` to a phys.addr `p`:

```
split p into segment number (s) and
    address within segment (a)

if a >= L_s, then generate exception
else
    p = a + R_i
```

* As for dynamic relocation, the kernel maintains a separate set of relocation offsets and limits for each process
    - also changes the values in the MMU's registers when there is a context switch between processes
* We never allocate memory for address space(s) we don't use
* Amount of data we need to store to manage these extra limits and offsets is negligible (relative to the entire memory system)


#### Segmentation Fault

* Attempting to read or write to an address that is not in a segment for which you have permission to do so
    - read/write memory outside of your segments


#### Segmented Address Translation Example


```
Limit Reg 0: 0x2000 ; Reloc Reg 0: 0x3 8000
Limit Reg 1: 0x5000 ; Reloc Reg 1: 0x1 0000

Only two segments in address space, so...
    \# bits for seg.num = 1

v = 0x1240 = 0001 0010 0100 0000
; segment = 0
; offset = 0x1240
; p = 0x39240

v=0xa0a0 = __1__010 0000 1010 0000
; segment = 1
; offset = 010 0000 1010 0000 = 0x20a0
; p = 0x120a0

v = 0x66ac
; segment = 0
; offset = 0x66a0
; outside of limit : exception

v = 0xe880
; segment = 1
; offset = 0x6880
; outside of limit : exception

__note__
if addr cannot be translated
    exception
else
    ...
```


#### Problem(s)

We've solved the issue of allocation egregious amounts of unused memory, but we've introduced the problem of externel fragmentation

* We are still trying to allocate contiguous regions of physical memory
    - these regions are variable in size
    - every process will have different code/data/stack segment sizes
    - when storing a new process and creating a new address space, the kernel tries to find a free segment of memory
        + if no contiguous region, can't start process
        + can defragmentate, but that affects performance
* External fragmentation can be solved
    - OS/161 uses segmented memory
        + different, though. Does not specifically encode a segment number
        + A3: combine segmentation with single-level paging
            * before, we had a single page table for the entire address space
            * when combining the two techniques, have a page table for each segment
                - 3 segments : 3 page tables
                - this works because we will now divide segments into pages and map each segment page to a physical frame (__no external fragmentation__)
                - and, our page table will only be tracking regions of the address space we're actually using


#### Two-Level Paging

* Instead of having a single page table to map an entire v.mem, we can split the page table into smaller page tables, and add a page table directory
    - instead of one large, contiguous table, we have multiple smaller tables
    - if all PTEs in a smaller table are invalid, we can avoid creating that table entirely
* lower level is where we map frames to pages
* upper level tells us if there are any valid mappings
    - if no valid mappings, won't create sub-page-table
* each v.addr has three parts (somewhat more complicated now)
    - level one page number
        + used to index the directory
    - level two page number
        + used to index a page table
    - offset within page

```
our v.addr looks something like

DDPP OOOO ...
```

__Old Example [vm_S36]__

We have a page table with 16 entries, but only 7 are valid

* We will have a directory with 2 page tables
    - Fewer invalid entries
    - Fewer total entries


#### Address Translation with Two-Level Paging

* The MMU's page table base register points to the page table directory for the current process
* Each virtual address v has three parts: `p1, p2, off`
* How the MMU translates a virtual memory
    - index into the page table directory using p1 to get a pointer to a 2nd level page table
        + directory indices store a pointer to a page table (or is NULL is no page table entry has no valid entries)
    - if the directory entry is not valid, raise exception
    - index into the 2nd level page table using p2 to find the PTE for the page being accessed
    - if the PTE is not valid, raise an exception
    - otherwise, combine the frame number from the PTE with `off` to determine the phys.addr (same as for single-level paging)


__Example [vm_S38]__

**The number of offset bits still depends on the page size**


#### Limits of Two-Level Paging

* One goal of two-level paging was to keep individual page tables small
* Suppose we have 40-bit virtual addresses (V=40)
    - size of a PTE is 4 bytes
    - page size is 4KB (2^12 bytes)
    - we'd like to limit each page table's size to 4KB
        + we want a page table to occupy a single page in memory
            * this is (more) efficient
            * if our page table occupied multiple pages, we'd have a bunch of TLB or some such page misses
            * page table size / pte entry size = # of entries that can fit in a page
* __Problem__
    - for large address spaces, we may need a alrge page table directory!
        + there can be up to 2^28 pages in a virtual memory with V=40
        + a single page table can hold 2^10 PTEs
        + we may need up to 2^18 page tables
        + our page table directory will have to have 2^18 entries
        + if a directory entry is 4 bytes, the directory will occupy 1MB
* this is the problem we were trying to avoid by introducing a second level